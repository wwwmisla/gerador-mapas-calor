{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# O que fazer inicialmente?\n",
        "\n",
        "\n",
        "* Obter um vídeo real com movimentação de pessoas;\n",
        "* Processar com YOLOv8 + rastreador (DeepSORT);\n",
        "* Extrair as posições de cada ID em cada frame;  \n",
        "* Plotar essas posições como mapa de calor;\n",
        "* Testar em outras situações."
      ],
      "metadata": {
        "id": "LTjutAAYnGU1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO2f2ikeK2In",
        "outputId": "9c60c795-5298-4fcd-e2ad-bb229c67ab8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.159-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting deep_sort_realtime\n",
            "  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.159-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, deep_sort_realtime, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed deep_sort_realtime-1.3.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.159 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "# Instalando as bibliotecas/dependências necessárias:\n",
        "\n",
        "!pip install ultralytics deep_sort_realtime opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload do vídeo\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Assumimos que só há um arquivo enviado e pegamos o nome:\n",
        "video_path = list(uploaded.keys())[0]\n",
        "print(\"Vídeo carregado:\", video_path)\n"
      ],
      "metadata": {
        "id": "N7EsEXygqxO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testando:\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Carregar o modelo YOLOv8 pré-treinado ---\n",
        "model = YOLO(\"yolov8n.pt\")  # \"n\" = nano, é leve\n",
        "\n",
        "# --- 2. Iniciar o DeepSORT para rastrear pessoas ---\n",
        "tracker = DeepSort(max_age=15)\n",
        "\n",
        "# --- 3. Carregar o vídeo ---\n",
        "video_path = \"/content/MOT20-01-raw.webm\"  # Caminho do vídeo\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Listas para armazenar posições rastreadas\n",
        "all_x = []\n",
        "all_y = []\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # --- 4. Rodar YOLOv8 para detectar pessoas ---\n",
        "    results = model(frame)[0]\n",
        "    detections = []\n",
        "\n",
        "    for result in results.boxes.data.tolist():\n",
        "        x1, y1, x2, y2, conf, cls = result\n",
        "        if int(cls) == 0:  # classe 0 = pessoa\n",
        "            detections.append(([x1, y1, x2 - x1, y2 - y1], conf, 'person'))\n",
        "\n",
        "    # --- 5. Atualizar o rastreador com as detecções ---\n",
        "    tracks = tracker.update_tracks(detections, frame=frame)\n",
        "\n",
        "    for track in tracks:\n",
        "        if not track.is_confirmed():\n",
        "            continue\n",
        "\n",
        "        track_id = track.track_id\n",
        "        ltrb = track.to_ltrb()  # left, top, right, bottom\n",
        "        x1, y1, x2, y2 = ltrb\n",
        "        cx = int((x1 + x2) / 2)\n",
        "        cy = int((y1 + y2) / 2)\n",
        "\n",
        "        all_x.append(cx)\n",
        "        all_y.append(cy)\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# --- 6. Criar o mapa de calor com os pontos acumulados ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist2d(all_x, all_y, bins=100, cmap='hot')\n",
        "plt.colorbar(label=\"Intensidade de presença\")\n",
        "plt.gca().invert_yaxis()  # Inverter eixo Y para coincidir com imagem\n",
        "plt.title(\"Mapa de Calor da Movimentação de Pessoas\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZUnzdG-mpYwD",
        "outputId": "e2d37499-fe4f-4515-cca5-92c7c3d3378e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 11.0ms\n",
            "Speed: 2.3ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 7.3ms\n",
            "Speed: 3.1ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 8.5ms\n",
            "Speed: 3.2ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 11.1ms\n",
            "Speed: 3.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 7.5ms\n",
            "Speed: 4.0ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 umbrella, 7.8ms\n",
            "Speed: 3.6ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 horses, 1 umbrella, 8.3ms\n",
            "Speed: 3.7ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 horse, 1 umbrella, 8.3ms\n",
            "Speed: 3.6ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 umbrella, 7.1ms\n",
            "Speed: 4.2ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 umbrella, 12.1ms\n",
            "Speed: 3.6ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 7.9ms\n",
            "Speed: 3.7ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 1 handbag, 12.5ms\n",
            "Speed: 3.0ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 umbrella, 7.9ms\n",
            "Speed: 3.8ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 13.1ms\n",
            "Speed: 3.3ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 12.1ms\n",
            "Speed: 3.4ms preprocess, 12.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 17.9ms\n",
            "Speed: 3.5ms preprocess, 17.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 1 handbag, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 1 handbag, 7.1ms\n",
            "Speed: 2.3ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 umbrella, 8.8ms\n",
            "Speed: 3.0ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 11.0ms\n",
            "Speed: 3.7ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 7.9ms\n",
            "Speed: 2.6ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 8.5ms\n",
            "Speed: 3.0ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 10.6ms\n",
            "Speed: 2.9ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 12.4ms\n",
            "Speed: 3.7ms preprocess, 12.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 7.3ms\n",
            "Speed: 3.3ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 8.5ms\n",
            "Speed: 3.1ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 19.8ms\n",
            "Speed: 10.2ms preprocess, 19.8ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 19.3ms\n",
            "Speed: 6.1ms preprocess, 19.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 27.1ms\n",
            "Speed: 9.4ms preprocess, 27.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 handbag, 9.5ms\n",
            "Speed: 3.8ms preprocess, 9.5ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 18.0ms\n",
            "Speed: 6.1ms preprocess, 18.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 24.5ms\n",
            "Speed: 6.7ms preprocess, 24.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 16.5ms\n",
            "Speed: 3.6ms preprocess, 16.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 20.9ms\n",
            "Speed: 3.6ms preprocess, 20.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 1 handbag, 9.5ms\n",
            "Speed: 3.5ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 1 handbag, 24.9ms\n",
            "Speed: 3.4ms preprocess, 24.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 1 handbag, 28.6ms\n",
            "Speed: 3.3ms preprocess, 28.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 1 handbag, 21.1ms\n",
            "Speed: 4.8ms preprocess, 21.1ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 1 handbag, 15.9ms\n",
            "Speed: 7.9ms preprocess, 15.9ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 30.8ms\n",
            "Speed: 6.3ms preprocess, 30.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 handbag, 10.8ms\n",
            "Speed: 3.8ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 handbag, 20.3ms\n",
            "Speed: 3.6ms preprocess, 20.3ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 23.5ms\n",
            "Speed: 4.1ms preprocess, 23.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 1 handbag, 22.2ms\n",
            "Speed: 3.5ms preprocess, 22.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 1 handbag, 23.7ms\n",
            "Speed: 14.9ms preprocess, 23.7ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 8.6ms\n",
            "Speed: 4.8ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 8.3ms\n",
            "Speed: 4.1ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 8.6ms\n",
            "Speed: 3.5ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 8.4ms\n",
            "Speed: 3.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 8.7ms\n",
            "Speed: 5.6ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 9.5ms\n",
            "Speed: 3.3ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 8.4ms\n",
            "Speed: 3.3ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 8.9ms\n",
            "Speed: 3.7ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 8.5ms\n",
            "Speed: 3.2ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 8.5ms\n",
            "Speed: 3.5ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 14.8ms\n",
            "Speed: 3.2ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 25.1ms\n",
            "Speed: 3.8ms preprocess, 25.1ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 8.6ms\n",
            "Speed: 3.2ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 8.3ms\n",
            "Speed: 3.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 9.0ms\n",
            "Speed: 4.7ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 9.0ms\n",
            "Speed: 4.5ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 8.6ms\n",
            "Speed: 4.8ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 12.2ms\n",
            "Speed: 5.3ms preprocess, 12.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 8.5ms\n",
            "Speed: 3.6ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 9.6ms\n",
            "Speed: 3.5ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 tv, 17.4ms\n",
            "Speed: 3.9ms preprocess, 17.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 tv, 9.1ms\n",
            "Speed: 6.0ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 tv, 8.7ms\n",
            "Speed: 3.8ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 tv, 11.5ms\n",
            "Speed: 3.6ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 tvs, 8.9ms\n",
            "Speed: 3.1ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 tv, 10.6ms\n",
            "Speed: 3.6ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 tv, 12.5ms\n",
            "Speed: 4.0ms preprocess, 12.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 handbag, 1 tv, 9.6ms\n",
            "Speed: 4.1ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 1 tv, 8.9ms\n",
            "Speed: 3.3ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 1 tv, 10.1ms\n",
            "Speed: 4.6ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 1 tv, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 1 tv, 9.8ms\n",
            "Speed: 3.4ms preprocess, 9.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 1 clock, 8.5ms\n",
            "Speed: 3.8ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 8.8ms\n",
            "Speed: 4.1ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 12.4ms\n",
            "Speed: 4.7ms preprocess, 12.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 8.6ms\n",
            "Speed: 3.0ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 8.3ms\n",
            "Speed: 3.4ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 8.7ms\n",
            "Speed: 3.6ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 8.7ms\n",
            "Speed: 3.4ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 handbag, 8.5ms\n",
            "Speed: 3.4ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 handbag, 23.4ms\n",
            "Speed: 3.2ms preprocess, 23.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 handbag, 9.3ms\n",
            "Speed: 13.1ms preprocess, 9.3ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 handbag, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 8.6ms\n",
            "Speed: 3.5ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 9.7ms\n",
            "Speed: 4.1ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 8.2ms\n",
            "Speed: 5.1ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 12.7ms\n",
            "Speed: 5.5ms preprocess, 12.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 tv, 10.2ms\n",
            "Speed: 5.1ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 handbags, 1 tv, 8.9ms\n",
            "Speed: 4.6ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 handbags, 2 tvs, 14.9ms\n",
            "Speed: 13.0ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 tv, 14.2ms\n",
            "Speed: 3.5ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 handbag, 1 tv, 12.7ms\n",
            "Speed: 3.2ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 handbag, 1 tv, 9.0ms\n",
            "Speed: 3.4ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 handbag, 1 tv, 8.4ms\n",
            "Speed: 3.1ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 handbag, 8.7ms\n",
            "Speed: 3.4ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 handbag, 1 tv, 10.4ms\n",
            "Speed: 3.7ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 handbag, 1 tv, 9.6ms\n",
            "Speed: 4.6ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 1 tv, 9.0ms\n",
            "Speed: 3.9ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 2 tvs, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 1 handbag, 3 tvs, 9.1ms\n",
            "Speed: 3.6ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 handbag, 1 tv, 8.4ms\n",
            "Speed: 3.3ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 handbag, 1 tv, 9.2ms\n",
            "Speed: 3.9ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 1 handbag, 1 tv, 8.6ms\n",
            "Speed: 5.6ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 1 handbag, 1 tv, 10.4ms\n",
            "Speed: 3.9ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 1 handbag, 1 tv, 11.9ms\n",
            "Speed: 3.9ms preprocess, 11.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 1 handbag, 2 tvs, 8.7ms\n",
            "Speed: 3.0ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 1 umbrella, 1 handbag, 1 tv, 8.5ms\n",
            "Speed: 2.8ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 1 tv, 9.0ms\n",
            "Speed: 3.9ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 umbrella, 1 handbag, 2 tvs, 8.4ms\n",
            "Speed: 3.6ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 umbrella, 1 handbag, 2 tvs, 1 clock, 10.3ms\n",
            "Speed: 6.4ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 1 handbag, 1 tv, 8.8ms\n",
            "Speed: 3.8ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 2 handbags, 2 tvs, 8.7ms\n",
            "Speed: 3.4ms preprocess, 8.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 1 umbrella, 1 handbag, 2 tvs, 12.6ms\n",
            "Speed: 4.1ms preprocess, 12.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 1 umbrella, 1 handbag, 1 tv, 8.7ms\n",
            "Speed: 3.3ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 umbrella, 1 handbag, 1 tv, 8.4ms\n",
            "Speed: 3.3ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 umbrella, 1 handbag, 1 tv, 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 umbrella, 1 handbag, 2 tvs, 8.5ms\n",
            "Speed: 3.2ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 umbrella, 1 handbag, 1 tv, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 1 handbag, 8.4ms\n",
            "Speed: 3.3ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 1 handbag, 1 tv, 1 clock, 8.9ms\n",
            "Speed: 5.8ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 1 handbag, 2 tvs, 25.3ms\n",
            "Speed: 3.2ms preprocess, 25.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 1 handbag, 8.6ms\n",
            "Speed: 3.7ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 1 handbag, 1 tv, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 umbrella, 1 handbag, 1 tv, 8.8ms\n",
            "Speed: 4.6ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 umbrella, 1 handbag, 1 tv, 8.7ms\n",
            "Speed: 3.4ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 umbrella, 1 handbag, 1 tv, 8.8ms\n",
            "Speed: 3.3ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 1 handbag, 9.4ms\n",
            "Speed: 4.5ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 1 handbag, 10.6ms\n",
            "Speed: 4.8ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 1 handbag, 9.0ms\n",
            "Speed: 5.0ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 1 umbrella, 1 handbag, 19.2ms\n",
            "Speed: 3.7ms preprocess, 19.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 umbrella, 1 handbag, 8.5ms\n",
            "Speed: 3.1ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 1 handbag, 8.2ms\n",
            "Speed: 5.6ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 2 handbags, 9.3ms\n",
            "Speed: 3.5ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 1 handbag, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 2 handbags, 1 tv, 8.9ms\n",
            "Speed: 3.4ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 1 handbag, 1 tv, 8.6ms\n",
            "Speed: 3.5ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 1 handbag, 9.2ms\n",
            "Speed: 5.5ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 12.9ms\n",
            "Speed: 6.3ms preprocess, 12.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 17.3ms\n",
            "Speed: 9.5ms preprocess, 17.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 1 handbag, 1 clock, 22.5ms\n",
            "Speed: 3.5ms preprocess, 22.5ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 15.1ms\n",
            "Speed: 3.2ms preprocess, 15.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 12.9ms\n",
            "Speed: 11.2ms preprocess, 12.9ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 horse, 21.9ms\n",
            "Speed: 10.1ms preprocess, 21.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 14.1ms\n",
            "Speed: 10.2ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 24.2ms\n",
            "Speed: 3.3ms preprocess, 24.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 15.6ms\n",
            "Speed: 5.5ms preprocess, 15.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 15.3ms\n",
            "Speed: 3.1ms preprocess, 15.3ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 24.8ms\n",
            "Speed: 7.1ms preprocess, 24.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 umbrella, 29.2ms\n",
            "Speed: 4.6ms preprocess, 29.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 umbrella, 17.8ms\n",
            "Speed: 5.2ms preprocess, 17.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 28.8ms\n",
            "Speed: 3.2ms preprocess, 28.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 38.7ms\n",
            "Speed: 3.2ms preprocess, 38.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 10.2ms\n",
            "Speed: 3.9ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 25.7ms\n",
            "Speed: 3.0ms preprocess, 25.7ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 8.6ms\n",
            "Speed: 3.1ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 8.7ms\n",
            "Speed: 5.8ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 13.8ms\n",
            "Speed: 6.2ms preprocess, 13.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 14.3ms\n",
            "Speed: 10.5ms preprocess, 14.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 umbrella, 9.3ms\n",
            "Speed: 3.6ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 9.3ms\n",
            "Speed: 8.1ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 13.0ms\n",
            "Speed: 3.3ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 11.0ms\n",
            "Speed: 2.9ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 10.9ms\n",
            "Speed: 3.9ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 10.0ms\n",
            "Speed: 2.8ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 8.5ms\n",
            "Speed: 2.9ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 11.7ms\n",
            "Speed: 8.0ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 umbrella, 8.8ms\n",
            "Speed: 5.9ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 1 clock, 8.8ms\n",
            "Speed: 3.4ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 18.2ms\n",
            "Speed: 6.5ms preprocess, 18.2ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 10.4ms\n",
            "Speed: 4.4ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 9.7ms\n",
            "Speed: 6.4ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 16.0ms\n",
            "Speed: 3.2ms preprocess, 16.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 9.3ms\n",
            "Speed: 8.0ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 9.2ms\n",
            "Speed: 3.6ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 8.7ms\n",
            "Speed: 7.8ms preprocess, 8.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 1 handbag, 8.5ms\n",
            "Speed: 3.6ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 1 handbag, 9.4ms\n",
            "Speed: 4.0ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 1 tv, 10.1ms\n",
            "Speed: 3.4ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 13.2ms\n",
            "Speed: 4.2ms preprocess, 13.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 8.6ms\n",
            "Speed: 3.5ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 horse, 1 umbrella, 15.0ms\n",
            "Speed: 3.2ms preprocess, 15.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 2 handbags, 8.3ms\n",
            "Speed: 3.6ms preprocess, 8.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 umbrella, 8.7ms\n",
            "Speed: 3.3ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 13.1ms\n",
            "Speed: 5.8ms preprocess, 13.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 8.5ms\n",
            "Speed: 3.9ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 12.7ms\n",
            "Speed: 5.5ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 11.0ms\n",
            "Speed: 4.1ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 handbag, 2 tvs, 8.8ms\n",
            "Speed: 4.6ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 tv, 9.0ms\n",
            "Speed: 6.5ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 15.5ms\n",
            "Speed: 3.6ms preprocess, 15.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 8.4ms\n",
            "Speed: 5.0ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 9.1ms\n",
            "Speed: 4.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 9.5ms\n",
            "Speed: 6.9ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 tv, 9.4ms\n",
            "Speed: 5.7ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 tv, 10.6ms\n",
            "Speed: 6.9ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 tv, 1 clock, 8.8ms\n",
            "Speed: 6.3ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 tvs, 9.4ms\n",
            "Speed: 13.6ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 8.6ms\n",
            "Speed: 6.6ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 tv, 8.6ms\n",
            "Speed: 3.6ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 tv, 8.3ms\n",
            "Speed: 3.4ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 tv, 8.4ms\n",
            "Speed: 3.5ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 tv, 28.1ms\n",
            "Speed: 3.6ms preprocess, 28.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 tvs, 12.3ms\n",
            "Speed: 3.6ms preprocess, 12.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 tvs, 9.5ms\n",
            "Speed: 3.7ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 tvs, 9.0ms\n",
            "Speed: 4.5ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 tvs, 1 clock, 9.3ms\n",
            "Speed: 3.6ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 tvs, 16.1ms\n",
            "Speed: 3.8ms preprocess, 16.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 tvs, 8.7ms\n",
            "Speed: 3.6ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 tvs, 8.7ms\n",
            "Speed: 5.7ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 tvs, 22.3ms\n",
            "Speed: 5.0ms preprocess, 22.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 tv, 8.9ms\n",
            "Speed: 3.4ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 tv, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 tv, 8.9ms\n",
            "Speed: 7.6ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 tv, 9.3ms\n",
            "Speed: 3.4ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 tvs, 12.2ms\n",
            "Speed: 11.9ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 tv, 9.5ms\n",
            "Speed: 3.8ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 tvs, 9.2ms\n",
            "Speed: 6.5ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 tvs, 12.8ms\n",
            "Speed: 6.6ms preprocess, 12.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 tvs, 8.5ms\n",
            "Speed: 6.4ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 tvs, 8.3ms\n",
            "Speed: 6.8ms preprocess, 8.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 tvs, 9.0ms\n",
            "Speed: 6.5ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 tv, 9.4ms\n",
            "Speed: 6.7ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 tv, 9.1ms\n",
            "Speed: 6.9ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 tvs, 9.3ms\n",
            "Speed: 6.7ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 tv, 9.3ms\n",
            "Speed: 5.4ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 tv, 12.7ms\n",
            "Speed: 11.6ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 tv, 9.9ms\n",
            "Speed: 3.7ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 tv, 8.6ms\n",
            "Speed: 6.8ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 tvs, 8.8ms\n",
            "Speed: 10.6ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 tvs, 17.9ms\n",
            "Speed: 7.2ms preprocess, 17.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 tvs, 8.7ms\n",
            "Speed: 3.6ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 tvs, 21.8ms\n",
            "Speed: 6.1ms preprocess, 21.8ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 tvs, 27.3ms\n",
            "Speed: 3.6ms preprocess, 27.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 tvs, 21.5ms\n",
            "Speed: 5.5ms preprocess, 21.5ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 tvs, 28.5ms\n",
            "Speed: 4.4ms preprocess, 28.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 2 tvs, 27.0ms\n",
            "Speed: 6.1ms preprocess, 27.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 tvs, 14.7ms\n",
            "Speed: 11.2ms preprocess, 14.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 tvs, 36.4ms\n",
            "Speed: 3.2ms preprocess, 36.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 tvs, 27.5ms\n",
            "Speed: 3.3ms preprocess, 27.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 tvs, 12.0ms\n",
            "Speed: 6.6ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 tv, 22.5ms\n",
            "Speed: 6.7ms preprocess, 22.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 tv, 19.1ms\n",
            "Speed: 3.2ms preprocess, 19.1ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 tvs, 9.6ms\n",
            "Speed: 5.7ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 tvs, 17.0ms\n",
            "Speed: 5.4ms preprocess, 17.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 tvs, 15.1ms\n",
            "Speed: 7.0ms preprocess, 15.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 tvs, 28.2ms\n",
            "Speed: 4.3ms preprocess, 28.2ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 tvs, 25.1ms\n",
            "Speed: 6.4ms preprocess, 25.1ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 tvs, 9.5ms\n",
            "Speed: 3.6ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 tvs, 9.4ms\n",
            "Speed: 3.9ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 tvs, 9.4ms\n",
            "Speed: 3.8ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 tvs, 8.8ms\n",
            "Speed: 3.6ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 motorcycle, 2 tvs, 8.5ms\n",
            "Speed: 6.2ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 tvs, 8.9ms\n",
            "Speed: 4.8ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 tvs, 12.9ms\n",
            "Speed: 3.3ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 tvs, 13.2ms\n",
            "Speed: 3.9ms preprocess, 13.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 tvs, 9.7ms\n",
            "Speed: 3.8ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 tvs, 10.0ms\n",
            "Speed: 3.9ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 tvs, 8.6ms\n",
            "Speed: 3.5ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 tvs, 9.0ms\n",
            "Speed: 4.5ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 tvs, 8.4ms\n",
            "Speed: 5.1ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 tvs, 12.4ms\n",
            "Speed: 3.9ms preprocess, 12.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 tvs, 32.9ms\n",
            "Speed: 3.4ms preprocess, 32.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 tvs, 9.3ms\n",
            "Speed: 4.4ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 tvs, 8.7ms\n",
            "Speed: 6.7ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 tvs, 8.9ms\n",
            "Speed: 4.5ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 tvs, 10.5ms\n",
            "Speed: 3.4ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 tvs, 8.8ms\n",
            "Speed: 6.2ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 tvs, 8.3ms\n",
            "Speed: 3.3ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 tvs, 8.6ms\n",
            "Speed: 3.0ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 3 tvs, 8.8ms\n",
            "Speed: 3.5ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 2 tvs, 8.8ms\n",
            "Speed: 3.2ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 3 tvs, 9.1ms\n",
            "Speed: 3.4ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 3 tvs, 10.5ms\n",
            "Speed: 7.1ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 2 tvs, 9.0ms\n",
            "Speed: 3.4ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 2 tvs, 9.1ms\n",
            "Speed: 3.4ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 3 tvs, 8.6ms\n",
            "Speed: 3.3ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 backpack, 3 tvs, 26.4ms\n",
            "Speed: 10.9ms preprocess, 26.4ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 backpack, 1 handbag, 1 tv, 8.6ms\n",
            "Speed: 3.5ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 handbag, 1 tv, 8.5ms\n",
            "Speed: 3.4ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 backpacks, 1 handbag, 2 tvs, 9.0ms\n",
            "Speed: 3.5ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 tvs, 8.6ms\n",
            "Speed: 6.9ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 2 tvs, 11.3ms\n",
            "Speed: 6.1ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 umbrella, 2 tvs, 9.5ms\n",
            "Speed: 7.7ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 umbrella, 1 handbag, 2 tvs, 8.6ms\n",
            "Speed: 3.4ms preprocess, 8.6ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 umbrella, 1 handbag, 2 tvs, 8.8ms\n",
            "Speed: 3.1ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 backpack, 1 umbrella, 1 handbag, 2 tvs, 8.5ms\n",
            "Speed: 2.9ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 umbrella, 1 tv, 8.5ms\n",
            "Speed: 3.5ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 1 backpack, 1 umbrella, 2 tvs, 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 backpack, 1 umbrella, 1 tv, 12.8ms\n",
            "Speed: 4.1ms preprocess, 12.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 umbrella, 2 tvs, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 umbrella, 2 tvs, 9.0ms\n",
            "Speed: 3.9ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 umbrella, 2 tvs, 10.0ms\n",
            "Speed: 4.2ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 umbrella, 2 tvs, 8.6ms\n",
            "Speed: 6.3ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 umbrella, 2 tvs, 9.9ms\n",
            "Speed: 3.7ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 umbrella, 2 tvs, 9.7ms\n",
            "Speed: 3.6ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 umbrella, 2 tvs, 8.6ms\n",
            "Speed: 4.0ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 umbrella, 2 tvs, 11.8ms\n",
            "Speed: 4.3ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 2 tvs, 10.2ms\n",
            "Speed: 4.3ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 umbrella, 8.4ms\n",
            "Speed: 3.3ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 umbrella, 10.5ms\n",
            "Speed: 5.3ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 umbrella, 1 tv, 11.2ms\n",
            "Speed: 2.8ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 1 tv, 10.4ms\n",
            "Speed: 3.7ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 12.3ms\n",
            "Speed: 4.2ms preprocess, 12.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 9.3ms\n",
            "Speed: 3.2ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 9.1ms\n",
            "Speed: 3.5ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.5ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 backpack, 1 umbrella, 8.8ms\n",
            "Speed: 4.0ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 backpack, 1 umbrella, 8.3ms\n",
            "Speed: 3.4ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 8.6ms\n",
            "Speed: 3.0ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 10.8ms\n",
            "Speed: 6.9ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 13.1ms\n",
            "Speed: 3.0ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 12.5ms\n",
            "Speed: 2.8ms preprocess, 12.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 umbrella, 9.3ms\n",
            "Speed: 3.6ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 8.6ms\n",
            "Speed: 4.0ms preprocess, 8.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 backpack, 1 umbrella, 9.1ms\n",
            "Speed: 3.7ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 backpack, 1 umbrella, 8.6ms\n",
            "Speed: 3.5ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 umbrella, 12.2ms\n",
            "Speed: 3.6ms preprocess, 12.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 umbrella, 10.2ms\n",
            "Speed: 2.7ms preprocess, 10.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 umbrella, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 umbrella, 52.9ms\n",
            "Speed: 8.6ms preprocess, 52.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 1 umbrella, 18.7ms\n",
            "Speed: 4.9ms preprocess, 18.7ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 umbrella, 29.8ms\n",
            "Speed: 4.4ms preprocess, 29.8ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 umbrella, 18.8ms\n",
            "Speed: 3.7ms preprocess, 18.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 umbrella, 32.5ms\n",
            "Speed: 3.7ms preprocess, 32.5ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 umbrella, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 umbrella, 18.2ms\n",
            "Speed: 3.8ms preprocess, 18.2ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 umbrella, 14.2ms\n",
            "Speed: 3.6ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 umbrella, 20.3ms\n",
            "Speed: 4.9ms preprocess, 20.3ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 umbrella, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 16.0ms\n",
            "Speed: 3.1ms preprocess, 16.0ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 31.3ms\n",
            "Speed: 7.9ms preprocess, 31.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 8.7ms\n",
            "Speed: 3.5ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 8.7ms\n",
            "Speed: 3.4ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 8.6ms\n",
            "Speed: 3.2ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 9.8ms\n",
            "Speed: 3.6ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 9.6ms\n",
            "Speed: 7.9ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 umbrella, 9.4ms\n",
            "Speed: 3.8ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 8.5ms\n",
            "Speed: 3.4ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 8.8ms\n",
            "Speed: 3.3ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 9.3ms\n",
            "Speed: 5.1ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 umbrella, 12.0ms\n",
            "Speed: 4.4ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 umbrella, 9.2ms\n",
            "Speed: 5.0ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 10.8ms\n",
            "Speed: 3.2ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 8.9ms\n",
            "Speed: 3.4ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 9.5ms\n",
            "Speed: 6.1ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 13.1ms\n",
            "Speed: 7.9ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 9.2ms\n",
            "Speed: 5.8ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 10.0ms\n",
            "Speed: 15.9ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 umbrella, 10.4ms\n",
            "Speed: 4.0ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 umbrella, 10.7ms\n",
            "Speed: 6.7ms preprocess, 10.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 umbrella, 19.3ms\n",
            "Speed: 3.3ms preprocess, 19.3ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 8.8ms\n",
            "Speed: 3.7ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 11.3ms\n",
            "Speed: 3.7ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 umbrella, 8.7ms\n",
            "Speed: 3.3ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 9.3ms\n",
            "Speed: 3.3ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 umbrella, 19.2ms\n",
            "Speed: 3.3ms preprocess, 19.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 8.5ms\n",
            "Speed: 4.6ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 10.2ms\n",
            "Speed: 3.7ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 8.6ms\n",
            "Speed: 3.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 22.1ms\n",
            "Speed: 3.5ms preprocess, 22.1ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 8.6ms\n",
            "Speed: 3.3ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 8.9ms\n",
            "Speed: 3.5ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 8.7ms\n",
            "Speed: 6.7ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 10.4ms\n",
            "Speed: 3.4ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 8.6ms\n",
            "Speed: 4.0ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 umbrella, 8.6ms\n",
            "Speed: 6.5ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 umbrella, 10.9ms\n",
            "Speed: 6.6ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 umbrella, 12.4ms\n",
            "Speed: 7.4ms preprocess, 12.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 10.1ms\n",
            "Speed: 3.3ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 9.7ms\n",
            "Speed: 7.6ms preprocess, 9.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 9.3ms\n",
            "Speed: 3.3ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 8.8ms\n",
            "Speed: 3.4ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 umbrella, 9.0ms\n",
            "Speed: 8.1ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 umbrella, 14.6ms\n",
            "Speed: 8.5ms preprocess, 14.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 9.6ms\n",
            "Speed: 3.5ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 umbrella, 9.0ms\n",
            "Speed: 3.8ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 8.8ms\n",
            "Speed: 2.8ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 umbrella, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 12.2ms\n",
            "Speed: 7.9ms preprocess, 12.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 10.1ms\n",
            "Speed: 3.5ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 umbrella, 9.2ms\n",
            "Speed: 3.6ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 umbrella, 9.2ms\n",
            "Speed: 3.7ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 28.4ms\n",
            "Speed: 3.4ms preprocess, 28.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 9.0ms\n",
            "Speed: 5.7ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 12.1ms\n",
            "Speed: 3.3ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 10.4ms\n",
            "Speed: 3.4ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 9.1ms\n",
            "Speed: 2.7ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 8.5ms\n",
            "Speed: 3.3ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 8.9ms\n",
            "Speed: 4.1ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 10.0ms\n",
            "Speed: 3.0ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 12.4ms\n",
            "Speed: 3.7ms preprocess, 12.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 8.9ms\n",
            "Speed: 7.2ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 8.6ms\n",
            "Speed: 7.6ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 9.1ms\n",
            "Speed: 8.3ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 9.3ms\n",
            "Speed: 3.8ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 16.7ms\n",
            "Speed: 3.9ms preprocess, 16.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 9.3ms\n",
            "Speed: 3.4ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 9.1ms\n",
            "Speed: 3.3ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 8.6ms\n",
            "Speed: 3.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 umbrella, 12.9ms\n",
            "Speed: 4.1ms preprocess, 12.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 9.0ms\n",
            "Speed: 4.6ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 9.0ms\n",
            "Speed: 3.9ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 umbrella, 8.4ms\n",
            "Speed: 3.3ms preprocess, 8.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 8.9ms\n",
            "Speed: 3.2ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 umbrella, 9.1ms\n",
            "Speed: 3.8ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 umbrella, 8.4ms\n",
            "Speed: 3.6ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 umbrella, 19.5ms\n",
            "Speed: 4.5ms preprocess, 19.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 8.4ms\n",
            "Speed: 3.5ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}