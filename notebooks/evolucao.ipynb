{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73fdd0c1",
   "metadata": {},
   "source": [
    "# A Evolução do Projeto: Gerador de Mapas de Calor\n",
    "\n",
    "Este notebook documenta a jornada de desenvolvimento do nosso sistema de análise de fluxo, desde a prova de conceito inicial até a lógica robusta que serve de base para a aplicação final em Gradio. Cada seção representa uma fase de experimentação, com seu código original e uma análise crítica dos resultados, sucessos e fracassos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19372d31",
   "metadata": {},
   "source": [
    "## Fase 1: O Rascunho Inicial (gerador_mapas_calor (rascunhos bases))\n",
    "\n",
    "**Objetivo:** Provar o conceito mais básico: é possível usar YOLO para detectar pessoas e plotar suas posições para criar algum tipo de mapa de calor?\n",
    "\n",
    "# O que fazer inicialmente?\n",
    "\n",
    "* Obter um vídeo real com movimentação de pessoas;\n",
    "* Processar com YOLOv8 + rastreador (DeepSORT);\n",
    "* Extrair as posições de cada ID em cada frame;  \n",
    "* Plotar essas posições como mapa de calor;\n",
    "* Testar em outras situações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d18d150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (8.3.167)\n",
      "Collecting deep_sort_realtime\n",
      "  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
      "     ---------------------------------------- 8.4/8.4 MB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: opencv-python in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from ultralytics) (2.2.6)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from ultralytics) (2.32.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from ultralytics) (1.16.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from ultralytics) (2.7.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from ultralytics) (0.22.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from ultralytics) (2.3.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
      "Requirement already satisfied: filelock in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\wwwmisla\\documents\\aprendizagem-programação\\projetos\\projects-ufrn\\visao-computacional\\gerador-mapas-calor\\venv\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Installing collected packages: deep_sort_realtime\n",
      "Successfully installed deep_sort_realtime-1.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Instalando as bibliotecas/dependências necessárias:\n",
    "\n",
    "!pip install ultralytics deep_sort_realtime opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36a94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload do vídeo\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Assumimos que só há um arquivo enviado e pegamos o nome:\n",
    "video_path = list(uploaded.keys())[0]\n",
    "print(\"Vídeo carregado:\", video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46149106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando:\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Carregar o modelo YOLOv8 pré-treinado ---\n",
    "model = YOLO(\"yolov8n.pt\")  # \"n\" = nano, é leve\n",
    "\n",
    "# --- 2. Iniciar o DeepSORT para rastrear pessoas ---\n",
    "tracker = DeepSort(max_age=15)\n",
    "\n",
    "# --- 3. Carregar o vídeo ---\n",
    "video_path = \"/content/MOT20-01-raw.webm\"  # Caminho do vídeo\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Listas para armazenar posições rastreadas\n",
    "all_x = []\n",
    "all_y = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # --- 4. Rodar YOLOv8 para detectar pessoas ---\n",
    "    results = model(frame)[0]\n",
    "    detections = []\n",
    "\n",
    "    for result in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, conf, cls = result\n",
    "        if int(cls) == 0:  # classe 0 = pessoa\n",
    "            detections.append(([x1, y1, x2 - x1, y2 - y1], conf, 'person'))\n",
    "\n",
    "    # --- 5. Atualizar o rastreador com as detecções ---\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        ltrb = track.to_ltrb()  # left, top, right, bottom\n",
    "        x1, y1, x2, y2 = ltrb\n",
    "        cx = int((x1 + x2) / 2)\n",
    "        cy = int((y1 + y2) / 2)\n",
    "\n",
    "        all_x.append(cx)\n",
    "        all_y.append(cy)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# --- 6. Criar o mapa de calor com os pontos acumulados ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist2d(all_x, all_y, bins=100, cmap='hot')\n",
    "plt.colorbar(label=\"Intensidade de presença\")\n",
    "plt.gca().invert_yaxis()  # Inverter eixo Y para coincidir com imagem\n",
    "plt.title(\"Mapa de Calor da Movimentação de Pessoas\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b96a731",
   "metadata": {},
   "source": [
    "### Análise da Fase 1\n",
    "\n",
    "***O que funcionou:**\n",
    "\n",
    "**- Prova de Conceito:** Sucesso! Conseguimos provar que era possível usar YOLO para detectar pessoas, um rastreador (DeepSORT) para segui-las e Matplotlib para gerar uma visualização baseada nas suas posições. O fluxo básico foi validado.\n",
    "\n",
    "**- Integração de Bibliotecas:** A integração entre ultralytics, deep_sort_realtime e matplotlib funcionou como esperado.\n",
    "\n",
    "**O que deu errado / Limitações:**\n",
    "\n",
    "**- Complexidade do DeepSORT:** A integração com o DeepSORT, embora funcional, exigia uma formatação de dados muito específica (detections.append(...)), tornando o código verboso e propenso a erros. Descobrimos mais tarde que o próprio YOLOv8 tinha um rastreador embutido muito mais simples de usar.\n",
    "\n",
    "**- Qualidade da Visualização:** O resultado final, usando plt.hist2d, não é um mapa de calor verdadeiro no contexto de visão computacional. É um histograma 2D, que cria uma imagem quadriculada e de baixa resolução. Ele não se sobrepõe ao vídeo e não tem a aparência suave e profissional que buscávamos.\n",
    "\n",
    "**- Eficiência:** O processo era lento e não havia otimizações como pular frames (FRAME_SKIP).\n",
    "\n",
    "**Conclusão:** Esta fase foi um sucesso como um primeiro passo, mas o resultado final era tecnicamente pobre e visualmente insatisfatório. Ficou claro que precisávamos de uma técnica de visualização melhor (com OpenCV) e um método de rastreamento mais simples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571799e7",
   "metadata": {},
   "source": [
    "## Fase 2: Refinamento e Feedback (map)\n",
    "\n",
    "**Objetivo:** Abandonar o hist2d em favor de uma sobreposição de mapa de calor real no vídeo. Implementar um rastreador mais simples e começar a extrair métricas quantitativas, incorporando o feedback do professor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ae7227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================\n",
    "# FASE 1: GERADOR DE MAPA DE CALOR ESTÁTICO - V1.1\n",
    "# DESCRIÇÃO: Script otimizado para gerar uma imagem de mapa de calor de alta qualidade\n",
    "#            e extrair dados quantitativos da análise de um arquivo de vídeo.\n",
    "# ==================================================================================================\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# 1. INSTALAÇÕES E IMPORTS\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "!pip install ultralytics tqdm -q\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from google.colab.patches import cv2_imshow\n",
    "import os\n",
    "from tqdm import tqdm # Para a barra de progresso\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# 2. CONFIGURAÇÃO CENTRALIZADA\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# Acesso ao Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "BASE_DIR = '/content/drive/MyDrive/visao_computacional/gerador-mapas-calor/Código/'\n",
    "VIDEO_PATH = os.path.join(BASE_DIR, 'videos/MOT20-01-raw.webm')\n",
    "RESULTS_PATH = os.path.join(BASE_DIR, 'resultados/')\n",
    "\n",
    "# --- Configurações do Modelo YOLO ---\n",
    "# Usando o 'yolov8n.pt' é leve, rápido e mais comum nas aplicações.\n",
    "MODEL_NAME = 'yolov8n.pt'\n",
    "CONF_THRESHOLD = 0.4 # Limiar de confiança: Apenas detecções com score > 0.4 são consideradas.\n",
    "\n",
    "# --- Configurações de Performance ---\n",
    "# Pula N frames para acelerar. 2 significa que 1 em cada 3 frames é analisado.\n",
    "FRAME_SKIP = 2\n",
    "\n",
    "# --- Configurações Visuais do Mapa de Calor ---\n",
    "# JUSTIFICATIVA: Um kernel grande (95,95) foi escolhido para criar manchas bem difusas,\n",
    "# ideal para visualizar aglomerações em vídeos de longa distância.\n",
    "GAUSSIAN_KERNEL_SIZE = (95, 95)\n",
    "# \"Força\" de cada ponto. Um valor maior torna as áreas de pico mais \"vermelhas\".\n",
    "HEAT_POINT_INTENSITY = 5\n",
    "# Transparência do mapa sobre o vídeo.\n",
    "HEATMAP_ALPHA = 0.4\n",
    "COLOR_MAP = cv2.COLORMAP_JET\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# 3. LÓGICA PRINCIPAL DO SCRIPT\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "\n",
    "def generate_static_heatmap():\n",
    "    \"\"\"\n",
    "    Função principal que encapsula a lógica para gerar o mapa de calor estático.\n",
    "    Ela processa um vídeo, coleta pontos de calor, gera uma imagem de sobreposição\n",
    "    e imprime uma análise quantitativa básica dos dados.\n",
    "    \"\"\"\n",
    "    os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "\n",
    "    # --- Carregamento e Verificação ---\n",
    "    print(f\"Carregando modelo '{MODEL_NAME}'...\")\n",
    "    model = YOLO(MODEL_NAME)\n",
    "\n",
    "    print(f\"Abrindo vídeo: '{VIDEO_PATH}'...\")\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    if not cap.isOpened():\n",
    "        print(\"ERRO CRÍTICO: Não foi possível abrir o arquivo de vídeo. Verifique o caminho.\")\n",
    "        return\n",
    "\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # --- Coleta de Pontos de Calor ---\n",
    "    heat_points = []\n",
    "    background_frame_captured = False # Flag para pegar o primeiro frame\n",
    "    background_frame = None\n",
    "    frames_processed_count = 0\n",
    "\n",
    "    with tqdm(total=total_frames, desc=\"Analisando vídeo\") as pbar:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                pbar.update(total_frames - pbar.n)\n",
    "                break\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "            # MELHORIA: Pega o primeiro frame válido como fundo e evita reabrir o vídeo\n",
    "            if not background_frame_captured:\n",
    "                background_frame = frame.copy()\n",
    "                background_frame_captured = True\n",
    "\n",
    "            # Pula frames conforme a configuração\n",
    "            if pbar.n % (FRAME_SKIP + 1) != 0:\n",
    "                continue\n",
    "\n",
    "            frames_processed_count += 1\n",
    "            results = model(frame, classes=[0], conf=CONF_THRESHOLD, verbose=False)\n",
    "\n",
    "            for r in results:\n",
    "                for box in r.boxes:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                    center_x, bottom_y = int((x1 + x2) / 2), int(y2)\n",
    "                    heat_points.append((center_x, bottom_y))\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # --- Geração do Mapa de Calor Visual ---\n",
    "    if not background_frame_captured:\n",
    "        print(\"ERRO: Não foi possível ler nenhum frame do vídeo para usar como fundo.\")\n",
    "        return\n",
    "\n",
    "    print(\"Gerando visualização do mapa de calor...\")\n",
    "    heatmap_matrix = np.zeros((frame_height, frame_width), dtype=np.float32)\n",
    "    for x, y in heat_points:\n",
    "        if 0 <= y < frame_height and 0 <= x < frame_width:\n",
    "            heatmap_matrix[y, x] += HEAT_POINT_INTENSITY\n",
    "\n",
    "    heatmap_matrix = cv2.GaussianBlur(heatmap_matrix, GAUSSIAN_KERNEL_SIZE, 0)\n",
    "    heatmap_normalized = cv2.normalize(heatmap_matrix, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    colored_heatmap = cv2.applyColorMap(heatmap_normalized, COLOR_MAP)\n",
    "    superimposed_img = cv2.addWeighted(background_frame, 1 - HEATMAP_ALPHA, colored_heatmap, HEATMAP_ALPHA, 0)\n",
    "\n",
    "    # --- Salvamento e Exibição ---\n",
    "    output_path = os.path.join(RESULTS_PATH, 'mapa_de_calor_ESTATICO_FINAL.png')\n",
    "    cv2.imwrite(output_path, superimposed_img)\n",
    "    print(f\"\\n✅ Visualização do mapa de calor salva em: {output_path}\")\n",
    "\n",
    "    display_height = 600\n",
    "    display_width = int(frame_width * (display_height / frame_height))\n",
    "    display_img = cv2.resize(superimposed_img, (display_width, display_height))\n",
    "    cv2_imshow(display_img)\n",
    "\n",
    "    # --- NOVA SEÇÃO: Análise Quantitativa (A cereja do bolo) ---\n",
    "    print(\"\\n--- Análise Quantitativa do Vídeo ---\")\n",
    "    total_detections = len(heat_points)\n",
    "    avg_detections_per_frame = total_detections / frames_processed_count if frames_processed_count > 0 else 0\n",
    "    print(f\"Total de frames no vídeo: {total_frames}\")\n",
    "    print(f\"Frames efetivamente analisados (considerando FRAME_SKIP={FRAME_SKIP}): {frames_processed_count}\")\n",
    "    print(f\"Total de detecções de pessoas: {total_detections}\")\n",
    "    print(f\"Média de pessoas detectadas por frame analisado: {avg_detections_per_frame:.2f}\")\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# 4. PONTO DE ENTRADA DO SCRIPT\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "    generate_static_heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb16e0a7",
   "metadata": {},
   "source": [
    "### Análise da Fase 2\n",
    "Esta fase representa um salto de qualidade significativo. Os códigos foram refinados, organizados em seções e funções, e o resultado visual começou a se parecer com o objetivo final.\n",
    "\n",
    "**O que funcionou:**\n",
    "\n",
    "**- Estrutura do Código:** A organização com configuração centralizada, funções e um ponto de entrada if __name__ == '__main__' tornou o código muito mais legível e profissional.\n",
    "\n",
    "**- Visualização com OpenCV:** A troca do hist2d pelo pipeline np.zeros -> GaussianBlur -> normalize -> applyColorMap -> addWeighted foi a decisão correta. Conseguimos gerar um mapa de calor suave e sobreposto ao vídeo.\n",
    "\n",
    "**- Introdução ao Rastreamento:** Os scripts seguintes nesta fase (não incluídos aqui, mas presentes no arquivo maps_1.ipynb) introduziram a ideia de rastreamento, mesmo que com um tracker SORT simplificado implementado manualmente. Isso nos forçou a pensar em como gerenciar IDs e trajetórias, um passo crucial.\n",
    "\n",
    "**- Análise de Dados:** A adição de gráficos com Matplotlib/Seaborn e a análise quantitativa mostraram o potencial do projeto para extrair insights reais, não apenas imagens bonitas.\n",
    "\n",
    "**O que deu errado / Limitações:**\n",
    "\n",
    "**- FALHA CONCEITUAL:** Detecção vs. Rastreamento: A primeira versão (V1.1, mostrada acima) ainda usava model(frame), que apenas detecta, não rastreia. Isso levou à percepção crítica de que a nossa \"Análise Quantitativa\" estava fundamentalmente errada, pois contava múltiplas detecções da mesma pessoa como eventos separados. Este foi o aprendizado mais importante da fase.\n",
    "\n",
    "**- Tracker Manual:** O tracker SORT que implementamos manualmente nas iterações seguintes era muito simplista. Ele perdia IDs facilmente se as pessoas se moviam rápido ou se sobrepunham, mostrando que precisávamos de uma solução mais robusta.\n",
    "\n",
    "**- Mapa de Calor de \"Presença\", não de \"Fluxo\":** Nossa técnica de heatmap, embora melhor, ainda era baseada em pontos de presença. Isso criava \"bolhas\" de calor onde as pessoas paravam, em vez de mostrar os \"caminhos\" do movimento. O feedback do professor e a análise das imagens de referência (MOT20-02) mostraram que precisávamos visualizar o fluxo.\n",
    "\n",
    "**Conclusão:** Esta fase foi essencial para refinar a técnica e, mais importante, para entender as limitações da nossa abordagem. Percebemos que precisávamos de um rastreador de verdade (como o embutido no YOLOv8) e de uma nova lógica de heatmap que visualizasse as trajetórias, e não os pontos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea97d6a",
   "metadata": {},
   "source": [
    "## Fase 3: A Lógica Final (gerador-mapas-calor - Códigos Finais)\n",
    "\n",
    "**Objetivo:** Sintetizar todos os aprendizados anteriores em um único notebook coeso, que implementa a lógica final e correta. Este código se tornaria a base exata para os módulos .py da aplicação Gradio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================\n",
    "# PROJETO: GERADOR DE MAPAS DE CALOR PARA OTIMIZAÇÃO DE ESPAÇOS PÚBLICOS\n",
    "# MÓDULO: NOTEBOOK DE EXPERIMENTAÇÃO FINAL (ADAPTATIVO E COM MÚLTIPLAS SAÍDAS)\n",
    "# VERSÃO: 13.0 - SÍNTESE FINAL, COM FOCO NA QUALIDADE VISUAL DE FLUXO\n",
    "#\n",
    "# DESCRIÇÃO: Esta versão final implementa a geração de múltiplos artefatos (vídeo de\n",
    "#            rastreamento e mapa de calor de fluxo) em uma única passagem. Crucialmente,\n",
    "#            utiliza a lógica correta de heatmap baseada no DESENHO DAS TRAJETÓRIAS com\n",
    "#            parâmetros visuais ADAPTATIVOS à escala da cena.\n",
    "# ==================================================================================================\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# 1. INSTALAÇÕES E IMPORTAÇÕES\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "!pip install ultralytics matplotlib tqdm -q\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "print(\"✅ Bibliotecas e dependências importadas.\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# 2. BLOCO DE CONFIGURAÇÃO CENTRALIZADA\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# --- Definição de Caminhos (Paths) ---\n",
    "BASE_DIR = '..'\n",
    "VIDEO_FILENAME = 'pessoas.mp4' # Teste com 'terminal.mp4' ou 'praca_europa.mp4'\n",
    "VIDEO_PATH = os.path.join(BASE_DIR, 'data', 'videos_publicos', VIDEO_FILENAME)\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, 'output')\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, 'heatmaps'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, 'tracked_videos'), exist_ok=True)\n",
    "\n",
    "# --- Configurações do Modelo e Rastreamento ---\n",
    "MODEL_NAME = 'yolov8s.pt'\n",
    "CONF_THRESHOLD = 0.3\n",
    "TRACKING_CLASSES = [0]\n",
    "FRAME_SKIP = 0\n",
    "\n",
    "# --- Parâmetros de Visualização (ADAPTATIVOS) ---\n",
    "# Fatores que serão multiplicados pela altura média das detecções.\n",
    "ADAPTIVE_LINE_FACTOR = 0.05 # A espessura da linha será 5% da altura média.\n",
    "ADAPTIVE_BLUR_FACTOR = 1.0  # O raio do blur será 100% da altura média.\n",
    "HEATMAP_ALPHA = 0.5\n",
    "COLOR_MAP = cv2.COLORMAP_JET\n",
    "\n",
    "print(\"✅ Parâmetros de configuração inicializados.\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# 3. FUNÇÕES MODULARIZADAS\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "\n",
    "def draw_tracking_annotations(frame, boxes_xyxy, track_ids, track_colors):\n",
    "    \"\"\"Desenha as anotações de rastreamento (caixas e IDs) de forma customizada.\"\"\"\n",
    "    for box, track_id in zip(boxes_xyxy, track_ids):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        if track_id not in track_colors:\n",
    "            track_colors[track_id] = (random.randint(30, 255), random.randint(30, 255), random.randint(30, 255))\n",
    "        color = track_colors[track_id]\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        label = f\"ID:{track_id}\"\n",
    "        (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "        cv2.rectangle(frame, (x1, y1 - h - 10), (x1 + w + 5, y1), color, -1)\n",
    "        cv2.putText(frame, label, (x1 + 5, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, lineType=cv2.LINE_AA)\n",
    "    return frame\n",
    "\n",
    "def process_video_single_pass(video_path, model, output_video_path, conf_threshold):\n",
    "    \"\"\"\n",
    "    Processa o vídeo em uma única passagem, gerando o vídeo de rastreamento\n",
    "    e coletando os dados para o mapa de calor (trajetórias e alturas).\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened(): raise IOError(f\"ERRO: Falha ao abrir o vídeo: {video_path}\")\n",
    "\n",
    "    w, h, fps = (int(cap.get(p)) for p in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "    out_video = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "\n",
    "    # AQUI ESTÁ A LÓGICA CORRETA: Coletamos a TRAJETÓRIA completa.\n",
    "    track_history = defaultdict(list)\n",
    "    detection_heights = []\n",
    "    track_colors = {}\n",
    "    first_frame = None\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    with tqdm(total=total_frames, desc=\"Processando Vídeo (Passagem Única)\") as pbar:\n",
    "        for frame_index in range(total_frames):\n",
    "            success, frame = cap.read()\n",
    "            if not success: break\n",
    "            if first_frame is None: first_frame = frame.copy()\n",
    "\n",
    "            results = model.track(frame, persist=True, classes=TRACKING_CLASSES, conf=conf_threshold, verbose=False)\n",
    "            annotated_frame = frame.copy()\n",
    "\n",
    "            if results[0].boxes.id is not None:\n",
    "                boxes_xyxy = results[0].boxes.xyxy.cpu().numpy()\n",
    "                boxes_xywh = results[0].boxes.xywh.cpu()\n",
    "                track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "                annotated_frame = draw_tracking_annotations(annotated_frame, boxes_xyxy, track_ids, track_colors)\n",
    "                \n",
    "                for box, track_id in zip(boxes_xywh, track_ids):\n",
    "                    center_point = (int(box[0]), int(box[1] + box[3] / 2))\n",
    "                    track_history[track_id].append(center_point)\n",
    "                    detection_heights.append(box[3])\n",
    "            \n",
    "            out_video.write(annotated_frame)\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    out_video.release()\n",
    "    \n",
    "    avg_height = np.mean(detection_heights) if detection_heights else 30.0\n",
    "    \n",
    "    print(\"✅ Processamento de passagem única concluído.\")\n",
    "    return track_history, first_frame, avg_height\n",
    "\n",
    "def generate_adaptive_flow_heatmap(background_frame, track_history, avg_height, line_factor, blur_factor):\n",
    "    \"\"\"\n",
    "    Gera o mapa de calor de DENSIDADE DE FLUXO desenhando as trajetórias e aplicando um blur adaptativo.\n",
    "    \"\"\"\n",
    "    if background_frame is None: raise ValueError(\"Frame de fundo é nulo.\")\n",
    "\n",
    "    h, w, _ = background_frame.shape\n",
    "    \n",
    "    # --- CÁLCULO DOS PARÂMETROS ADAPTATIVOS ---\n",
    "    line_thickness = max(1, int(avg_height * line_factor))\n",
    "    kernel_size = max(1, int(avg_height * blur_factor))\n",
    "    if kernel_size % 2 == 0: kernel_size += 1\n",
    "    gaussian_kernel = (kernel_size, kernel_size)\n",
    "    \n",
    "    print(f\"\\nAltura Média da Detecção: {avg_height:.2f}px.\")\n",
    "    print(f\"-> Espessura da Linha Adaptativa: {line_thickness}px\")\n",
    "    print(f\"-> Kernel de Blur Adaptativo: {gaussian_kernel}\")\n",
    "\n",
    "    # A LÓGICA CORRETA: Desenha as LINHAS da trajetória em um canvas.\n",
    "    trajectory_canvas = np.zeros((h, w), dtype=np.float32)\n",
    "    for path in track_history.values():\n",
    "        for i in range(len(path) - 1):\n",
    "            cv2.line(trajectory_canvas, path[i], path[i+1], 1.0, line_thickness)\n",
    "    \n",
    "    # Aplica o blur sobre as LINHAS para criar o efeito de \"calor\" de fluxo.\n",
    "    trajectory_canvas = cv2.GaussianBlur(trajectory_canvas, gaussian_kernel, 0)\n",
    "    \n",
    "    heatmap_norm = cv2.normalize(trajectory_canvas, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "    heatmap_color = cv2.applyColorMap(heatmap_norm, COLOR_MAP)\n",
    "\n",
    "    blended_image = cv2.addWeighted(background_frame, 1 - HEATMAP_ALPHA, heatmap_color, HEATMAP_ALPHA, 0)\n",
    "    print(\"✅ Mapa de calor de fluxo adaptativo gerado.\")\n",
    "    return blended_image\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "# 4. ORQUESTRAÇÃO E EXECUÇÃO DO EXPERIMENTO\n",
    "# --------------------------------------------------------------------------------------------------\n",
    "\n",
    "def run_full_analysis_pipeline():\n",
    "    \"\"\"Função principal que orquestra todo o processo.\"\"\"\n",
    "    base_filename = os.path.splitext(VIDEO_FILENAME)[0]\n",
    "    output_heatmap_path = os.path.join(OUTPUT_DIR, 'heatmaps', f\"{base_filename}_adaptive_flow_heatmap.png\")\n",
    "    output_video_path = os.path.join(OUTPUT_DIR, 'tracked_videos', f\"{base_filename}_tracked.mp4\")\n",
    "\n",
    "    model = YOLO(MODEL_NAME)\n",
    "\n",
    "    # Coleta as TRAJETÓRIAS completas.\n",
    "    track_history, first_frame, avg_height = process_video_single_pass(\n",
    "        VIDEO_PATH, model, output_video_path, CONF_THRESHOLD\n",
    "    )\n",
    "    print(f\"\\n-> Vídeo de rastreamento salvo em: '{output_video_path}'\")\n",
    "\n",
    "    # Usa a função correta para gerar o heatmap de FLUXO.\n",
    "    final_heatmap_image = generate_adaptive_flow_heatmap(\n",
    "        first_frame, track_history, avg_height, ADAPTIVE_LINE_FACTOR, ADAPTIVE_BLUR_FACTOR\n",
    "    )\n",
    "    \n",
    "    cv2.imwrite(output_heatmap_path, final_heatmap_image)\n",
    "    print(f\"-> Imagem do mapa de calor salva em: '{output_heatmap_path}'\")\n",
    "\n",
    "    heatmap_rgb = cv2.cvtColor(final_heatmap_image, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.imshow(heatmap_rgb)\n",
    "    plt.title(f\"Mapa de Calor de Fluxo Adaptativo - {VIDEO_FILENAME}\", fontsize=16)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_full_analysis_pipeline()\n",
    "    print(\"\\n--- FIM DA ETAPA DE EXPERIMENTAÇÃO. TODOS OS ARTEFATOS FORAM GERADOS. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b61f5b",
   "metadata": {},
   "source": [
    "### Análise da Fase 3 (e Versões Subsequentes)\n",
    "\n",
    "**O que funcionou (As Decisões Finais):**\n",
    "\n",
    "**- YOLOv8 Tracker Embutido:** A decisão de abandonar trackers externos (DeepSORT) ou manuais (SORT-like) em favor do model.track() do YOLOv8 foi a mais acertada. Simplificou o código drasticamente e se mostrou muito mais robusto e preciso.\n",
    "\n",
    "**- Lógica de Mapa de Calor de Fluxo:** A técnica de desenhar as linhas da trajetória em um canvas e depois aplicar um GaussianBlur foi a única que produziu o resultado visual desejado, replicando a aparência dos mapas de calor profissionais (MOT20-02).\n",
    "\n",
    "**- Parâmetros Adaptativos:** A introdução de parâmetros adaptativos (como ADAPTIVE_BLUR_FACTOR), que calculam o tamanho do blur e da linha com base na altura média das detecções, foi a chave para tornar a solução robusta e funcional para vídeos com diferentes escalas (câmeras de perto vs. de longe).\n",
    "\n",
    "**- Estrutura Modular:** Organizar o código em funções claras (process_video_..., generate_heatmap_..., run_experiment) tornou a lógica fácil de entender e, crucialmente, tornou a Etapa 2 (Refatoração) um processo trivial de copiar e colar para os arquivos .py.\n",
    "\n",
    "**O que deu errado (Bugs e Iterações durante o desenvolvimento):**\n",
    "\n",
    "**- Erros de Sintaxe:** Durante o desenvolvimento (como visto nas versões 8.x, 9.x), ocorreram bugs simples, mas bloqueantes, como is_opened vs isOpened ou NameError por esquecer de passar um parâmetro. Isso reforçou a importância de testar cada pequena mudança.\n",
    "\n",
    "**- Geração de Vídeo:** A geração do vídeo de rastreamento para a aplicação Gradio se mostrou um grande desafio. Problemas com codecs (mp4v vs XVID vs avc1) e alertas de antivírus no Windows (que bloqueavam a escrita de arquivos de vídeo) nos forçaram a iterar várias vezes até chegar à solução mais compatível.\n",
    "\n",
    "**- Qualidade Visual do Heatmap:** As primeiras versões do mapa de calor de fluxo ficavam \"desbotadas\". A solução foi adicionar um fator de ganho (Gain) para amplificar a intensidade do calor antes da colorização, garantindo cores vivas.\n",
    "\n",
    "**Conclusão Final:** Esta fase final de experimentação produziu uma lógica de análise completa, robusta e de alta qualidade. Ela resolveu todos os problemas conceituais e técnicos das fases anteriores e nos deu uma base sólida e confiável para construir a aplicação web final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf16db04",
   "metadata": {},
   "source": [
    "### Observações:\n",
    "\n",
    "Esses códigos são um pouco do processo de desenvolvimento (apesar de que hajam mais), fez-se interessante fazer esta linha do tempo para que houve-se um entendimento maior acerca do que estava sendo ou não realizado de forma eficiente.\n",
    "\n",
    "#### Etapas do Processo em que este notebook faz parte:\n",
    "\n",
    "✅ Etapa 0: Configuração Completa do Ambiente e Estrutura\n",
    "\n",
    "Ambiente virtual, dependências, estrutura de pastas e repositório organizados.\n",
    "\n",
    "✅ Etapa 1: A Fase de Experimentação (O Notebook)\n",
    "\n",
    "Testes com modelos de detecção, rastreamento e extração de dados em notebooks.\n",
    "\n",
    "A *Etapa 2* é referente a próxima parte do código em que pode ser localizada na pasta ```app```:\n",
    "\n",
    "🚧 Etapa 2: Refatorando o Código para Módulos Reutilizáveis\n",
    "\n",
    "Separação das funções em arquivos .py com foco em reutilização e clareza."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
